import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import joblib
import matplotlib

# ========================
# Function to train/evaluate model
# ========================
def train_model(X, y, model_name):
    if X.empty or y.empty:
        print(f"Error: No data available to train {model_name}.")
        return None

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # XGBoost model
    model = XGBRegressor(
        n_estimators=500,
        learning_rate=0.05,
        max_depth=6,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=-1
    )
    model.fit(X_train, y_train)

    # Error metrics on test set
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"\n{model_name} Performance on Test Set:")
    print(f"  MSE : {mse:.5f}")
    print(f"  RMSE: {rmse:.5f}")
    print(f"  MAE : {mae:.5f}")
    print(f"  R²  : {r2:.5f}")

    # Save metrics to file
    with open("model_performance.txt", "a") as f:
        f.write(f"{model_name} Performance on Test Set:\n")
        f.write(f"MSE : {mse:.5f}\nRMSE: {rmse:.5f}\nMAE : {mae:.5f}\nR²  : {r2:.5f}\n\n")

    # Feature importance plot
    importances = model.feature_importances_
    features = X.columns
    sorted_idx = np.argsort(importances)[::-1]

    plt.figure(figsize=(10, 6))
    plt.bar(range(len(features)), importances[sorted_idx], color="skyblue")
    plt.xticks(range(len(features)), features[sorted_idx], rotation=90)
    plt.title(f"Feature Importance ({model_name})")
    plt.tight_layout()
    plt.savefig(f"{model_name}_feature_importance.png")
    plt.close()

    joblib.dump(model, f"{model_name}.pkl")
    return model

# ========================
# Font fallback to avoid Times New Roman warnings
# ========================
available_fonts = [f.name for f in matplotlib.font_manager.fontManager.ttflist]
if "Times New Roman" in available_fonts:
    plt.rcParams["font.family"] = "Times New Roman"
else:
    plt.rcParams["font.family"] = "serif"
    plt.rcParams["font.serif"] = ["Times", "DejaVu Serif"]

# ========================
# Load main dataset
# ========================
print("Loading data from data_set.csv...")
df = pd.read_csv("data_set.csv")
if "Formula" not in df.columns:
    raise ValueError("Error: 'Formula' column not found in dataset.")

for col in df.columns:
    if col != "Formula":
        df[col] = pd.to_numeric(df[col], errors="coerce")

df.dropna(inplace=True)
if df.empty:
    raise ValueError("Error: Dataset is empty after cleaning.")

if "ZT" not in df.columns:
    raise ValueError("Error: 'ZT' column not found in main dataset.")

X = df.drop(columns=["ZT", "Formula"])
y = df["ZT"]

# Train or load initial model
try:
    initial_model = joblib.load("Initial_XGB_Model.pkl")
    print("Loaded saved Initial_XGB_Model.pkl")
except:
    print("Training model: Initial_XGB_Model...")
    initial_model = train_model(X, y, "Initial_XGB_Model")

# Predict full dataset
print("\nPredicting ZT values for full data_set.csv...")
df_pred = df.copy()
X_all = df_pred.drop(columns=["ZT", "Formula"])
pred_all = initial_model.predict(X_all)
df_pred["Predicted_ZT"] = pred_all
df_pred.to_csv("predicted_data_set_XGB.csv", index=False)
print("Full dataset predictions saved to predicted_data_set_XGB.csv")

# Metrics for full dataset
mse_full = mean_squared_error(df["ZT"], pred_all)
rmse_full = np.sqrt(mse_full)
mae_full = mean_absolute_error(df["ZT"], pred_all)
r2_full = r2_score(df["ZT"], pred_all)
with open("model_performance.txt", "a") as f:
    f.write("Error Metrics for Full data_set.csv Predictions:\n")
    f.write(f"MSE : {mse_full:.5f}\nRMSE: {rmse_full:.5f}\nMAE : {mae_full:.5f}\nR²  : {r2_full:.5f}\n\n")

# ========================
# Load oxide dataset
# ========================
print("\nLoading new dataset for specific oxides...")
df_oxides = pd.read_csv("oxides_data.csv")
if "Formula" not in df_oxides.columns:
    raise ValueError("Error: 'Formula' column not found in oxides dataset.")

for col in df_oxides.columns:
    if col != "Formula":
        df_oxides[col] = pd.to_numeric(df_oxides[col], errors="coerce")

df_oxides.dropna(inplace=True)
if df_oxides.empty:
    raise ValueError("Error: Oxides dataset is empty after cleaning.")

if "ZT" not in df_oxides.columns:
    raise ValueError("Error: 'ZT' column not found in oxides dataset.")

X_oxides = df_oxides.drop(columns=["ZT", "Formula"])
y_oxides = df_oxides["ZT"]

# Train or load oxide model
try:
    oxide_model = joblib.load("Oxide_XGB_Model.pkl")
    print("Loaded saved Oxide_XGB_Model.pkl")
except:
    print("Training model: Oxide_XGB_Model...")
    oxide_model = train_model(X_oxides, y_oxides, "Oxide_XGB_Model")

# Predict oxide dataset
print("\nPredicting ZT values for oxides_data.csv...")
df_ox_pred = df_oxides.copy()
X_ox_all = df_ox_pred.drop(columns=["ZT", "Formula"])
pred_ox_all = oxide_model.predict(X_ox_all)
df_ox_pred["Predicted_ZT"] = pred_ox_all
df_ox_pred.to_csv("predicted_oxides_data_XGB.csv", index=False)
print("Oxide dataset predictions saved to predicted_oxides_data_XGB.csv")

# Metrics for oxide dataset
mse_ox = mean_squared_error(df_oxides["ZT"], pred_ox_all)
rmse_ox = np.sqrt(mse_ox)
mae_ox = mean_absolute_error(df_oxides["ZT"], pred_ox_all)
r2_ox = r2_score(df_oxides["ZT"], pred_ox_all)
with open("model_performance.txt", "a") as f:
    f.write("Error Metrics for oxides_data.csv Predictions:\n")
    f.write(f"MSE : {mse_ox:.5f}\nRMSE: {rmse_ox:.5f}\nMAE : {mae_ox:.5f}\nR²  : {r2_ox:.5f}\n\n")

# ========================
# Predictions for target oxides
# ========================
print("\nPredicting ZT values for Li2O, Na2O, K2O, Rb2O, Cs2O, BaTa4Te3O17...")
target_formulas = ["Li2O", "Na2O", "K2O", "Rb2O", "Cs2O", "BaTa4Te3O17"]
df_target = df_oxides[df_oxides["Formula"].isin(target_formulas)].copy()

if not df_target.empty:
    X_target = df_target.drop(columns=["ZT", "Formula"])
    predicted_target = oxide_model.predict(X_target)
    df_target["Predicted_ZT"] = predicted_target

    # Error metrics
    mse_target = mean_squared_error(df_target["ZT"], predicted_target)
    rmse_target = np.sqrt(mse_target)
    mae_target = mean_absolute_error(df_target["ZT"], predicted_target)
    r2_target = r2_score(df_target["ZT"], predicted_target)

    print("\nError Metrics for Specific Oxides:")
    print(f"  MSE : {mse_target:.5f}")
    print(f"  RMSE: {rmse_target:.5f}")
    print(f"  MAE : {mae_target:.5f}")
    print(f"  R²  : {r2_target:.5f}")

    # Save metrics
    with open("model_performance.txt", "a") as f:
        f.write("Error Metrics for Specific Oxides:\n")
        f.write(f"MSE : {mse_target:.5f}\nRMSE: {rmse_target:.5f}\nMAE : {mae_target:.5f}\nR²  : {r2_target:.5f}\n\n")

    # Save predictions
    df_target.to_csv("predicted_specific_oxides_XGB.csv", index=False)
    print("Predictions for specific oxides saved to predicted_specific_oxides_XGB.csv.")

    # Scatter plot: Actual vs Predicted
    plt.figure(figsize=(8, 6))
    plt.scatter(df_target["ZT"], predicted_target, color="blue", alpha=0.6, label="Predicted vs Actual")
    plt.plot([min(df_target["ZT"]), max(df_target["ZT"])],
             [min(df_target["ZT"]), max(df_target["ZT"])],
             linestyle="--", color="red", label="Ideal")
    plt.xlabel("Actual ZT")
    plt.ylabel("Predicted ZT")
    plt.title("ZT Predictions for Specific Oxides (XGBoost)")
    plt.legend()
    plt.tight_layout()
    plt.savefig("ZT_predictions_specific_XGB.png")
    plt.close()
else:
    print("Warning: None of the target oxides found in dataset.")

print("\n✅ Training and prediction complete!")
